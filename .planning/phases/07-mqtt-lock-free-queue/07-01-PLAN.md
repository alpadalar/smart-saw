---
phase: 07-mqtt-lock-free-queue
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/services/iot/mqtt_client.py]
autonomous: true
---

<objective>
Replace `deque` + `asyncio.Lock` with lock-free `asyncio.Queue` for MQTT telemetry batching.

Purpose: Eliminate lock contention in 10 Hz data processing loop - `queue_telemetry()` currently blocks waiting for `_batch_lock`.
Output: Lock-free producer-consumer pattern where data processor never waits.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/services/iot/mqtt_client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace deque with asyncio.Queue</name>
  <files>src/services/iot/mqtt_client.py</files>
  <action>
  Replace batch queue implementation:

  1. Change `_batch_queue: deque` to `_batch_queue: asyncio.Queue` with maxsize=1000
  2. Remove `_batch_lock = asyncio.Lock()` - no longer needed
  3. Update `queue_telemetry()`:
     - Remove `async with self._batch_lock:` wrapper
     - Use `self._batch_queue.put_nowait(telemetry)` instead of `.append()`
     - Catch `asyncio.QueueFull` and store to offline (same as current overflow behavior)
  4. Update `_batch_sender_loop()`:
     - Instead of checking `len(self._batch_queue) > 0`, collect items using `get_nowait()` in a loop until `QueueEmpty`
     - Remove the `await self._send_batch()` call pattern
     - Inline the batch collection and sending logic
  5. Update `_send_batch()` and `_send_batch_internal()`:
     - Remove lock acquisition from `_send_batch()`
     - Modify to accept batch items as parameter or collect from queue directly
  6. Update `_flush_queue()`:
     - Remove lock wrapper
     - Drain queue using `get_nowait()` until `QueueEmpty`
  7. Update `get_stats()`:
     - Use `self._batch_queue.qsize()` instead of `len(self._batch_queue)`
     - Use `self._batch_queue.maxsize` instead of `self._batch_queue.maxlen`

  Key pattern:
  - Producer (data processor): `put_nowait()` - O(1), never blocks
  - Consumer (batch sender): `get_nowait()` in loop - collects available items

  Do NOT use `await queue.get()` with blocking - use `get_nowait()` in a non-blocking collection loop to match current batch-at-interval behavior.
  </action>
  <verify>python -c "from src.services.iot.mqtt_client import MQTTService; print('Import OK')"</verify>
  <done>MQTTService uses asyncio.Queue, no asyncio.Lock for batch operations, queue_telemetry never blocks</done>
</task>

<task type="auto">
  <name>Task 2: Verify integration with data processor</name>
  <files>src/services/processing/data_processor.py</files>
  <action>
  Verify the interface remains compatible:

  1. Read `data_processor.py` line ~200 where `mqtt_service.queue_telemetry()` is called
  2. Confirm no changes needed - the method signature remains `async def queue_telemetry(self, processed_data)`
  3. The only difference is internal: no lock wait on the producer side

  No code changes expected - this is verification only.
  </action>
  <verify>grep -n "queue_telemetry" src/services/processing/data_processor.py</verify>
  <done>Data processor calls queue_telemetry unchanged, method signature preserved</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.services.iot.mqtt_client import MQTTService"` succeeds
- [ ] No `asyncio.Lock` in mqtt_client.py (for batch operations)
- [ ] `asyncio.Queue` used for `_batch_queue`
- [ ] `queue_telemetry` uses `put_nowait()`
- [ ] Data processor import chain works: `python -c "from src.services.processing.data_processor import DataProcessingPipeline"`
</verification>

<success_criteria>
- All tasks completed
- MQTTService uses lock-free asyncio.Queue for batching
- queue_telemetry() never blocks on lock acquisition
- Interface compatibility preserved
</success_criteria>

<output>
After completion, create `.planning/phases/07-mqtt-lock-free-queue/07-01-SUMMARY.md`
</output>
