---
phase: 09-anomaly-manager-lock-consolidation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/anomaly/manager.py]
autonomous: true
---

<objective>
Consolidate 9 separate lock acquisitions into single lock acquisition in AnomalyManager.process_data().

Purpose: Reduce lock contention overhead in 10 Hz processing loop - currently acquiring manager lock 9 times per cycle for anomaly_states updates.
Output: Single lock acquisition per process_data() call, ~8 fewer lock operations per cycle.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-mqtt-lock-free-queue/07-01-SUMMARY.md
@.planning/phases/08-vibration-dbscan-to-iqr/08-01-SUMMARY.md

@src/anomaly/manager.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Consolidate lock acquisitions in process_data()</name>
  <files>src/anomaly/manager.py</files>
  <action>
Refactor AnomalyManager.process_data() to use single lock acquisition for anomaly_states update:

1. Remove the 9 individual `with self._lock:` blocks around each sensor's anomaly_states update (lines ~143, 152, 161, 170, 179, 188, 197, 206, 215)

2. Collect all results in a local dict first (already done as `results = {}`)

3. After ALL detector processing is complete (before callback section), add single lock acquisition:
```python
# Update all anomaly states atomically
with self._lock:
    self.anomaly_states.update(results)
```

4. Keep detector calls OUTSIDE the lock - they have their own internal locks

Structure should be:
```python
# Process all sensors (no manager lock needed here - detectors have own locks)
if 'serit_sapmasi' in data:
    value = data.get('serit_sapmasi', 0.0)
    self.detectors['serit_sapmasi'].add_data_point(value, is_cutting)
    is_anomaly = self.detectors['serit_sapmasi'].detect()
    results['SeritSapmasi'] = is_anomaly
# ... (repeat for all 9 sensors, NO lock per sensor)

# Single lock acquisition for all state updates
with self._lock:
    self.anomaly_states.update(results)

# Callbacks (outside lock)
if self._update_callback:
    ...
```

This reduces 9 lock acquisitions to 1 per process_data() call.
  </action>
  <verify>python -c "from src.anomaly.manager import AnomalyManager; m = AnomalyManager(); print('Import OK')"</verify>
  <done>AnomalyManager.process_data() has exactly 1 `with self._lock:` block for anomaly_states update</done>
</task>

<task type="auto">
  <name>Task 2: Verify application startup and anomaly detection</name>
  <files>src/anomaly/manager.py</files>
  <action>
1. Run application startup test:
   timeout 5 python run.py || true

2. Verify AnomalyManager initializes correctly

3. Count lock acquisitions in process_data() to confirm consolidation:
   grep -n "with self._lock:" src/anomaly/manager.py

Expected: Only 4 occurrences in manager.py:
- 1 in process_data() (the consolidated one)
- 1 in get_anomaly_states()
- 1 in reset_anomaly_states()
- 1 in get_stats()
  </action>
  <verify>grep -c "with self._lock:" src/anomaly/manager.py returns 4 (not 12)</verify>
  <done>Application starts without errors, lock count reduced from 12 to 4 in manager.py</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] AnomalyManager imports without errors
- [ ] process_data() uses single lock acquisition for anomaly_states
- [ ] Application starts without anomaly detection errors
- [ ] Lock count in manager.py is 4 (was 12)
</verification>

<success_criteria>

- All tasks completed
- Lock acquisitions in process_data() reduced from 9 to 1
- Anomaly detection still functions correctly
- No threading errors introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/09-anomaly-manager-lock-consolidation/09-01-SUMMARY.md`
</output>
